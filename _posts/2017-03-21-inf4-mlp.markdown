---
layout: post
modalID: modalMlp
permalink: /:categories/:slug/
main_title:  Inf4 - Machine Learning Practical
start_date:   2016-09-21
end_date:     2017-03-21
thumb_image_url: assets/post_assets/inf4-mlp/images/compressed/AUGM_FLIPPED_confusion_matrix.png
images:
  - {
    url: "assets/post_assets/inf4-mlp/images/compressed/cifar10_preview.png",
    caption: "CIFAR-10 classes with 10 examples of each.",
    id: "cifar10_preview"
  }
  - {
    url: "assets/post_assets/inf4-mlp/images/compressed/Batch_Normalization_a005_error_train.png",
    caption: "Comparison of training errors for densely connected neural networks using batch normalization and different number of layers.",
    id: "Batch_Normalization_a005_error_train"
  }
  - {
    url: "assets/post_assets/inf4-mlp/images/compressed/elastic_deformation_pre.png",
    caption: "Examples of digits in the MNIST dataset before data augmentation is applied.",
    id: "elastic_deformation_pre"
  }
  - {
    url: "assets/post_assets/inf4-mlp/images/compressed/accuracy_e200.png",
    caption: "Training (blue) and validation accuracy (purple) of a densely connected neural network, training for 200 epochs, displayed in TensorBoard.",
    id: "accuracy_e200"
  }
  - {
    url: "assets/post_assets/inf4-mlp/images/compressed/sample_results.png",
    caption: "Network configuration and results file generated at the end of the run. Due to availability of numerous machines without GPUs, I ran numerous smaller training sessions instead of one large job. Output files like these served the purpose of conveying the results quickly.",
    id: "sample_results"
  }
  - {
    url: "assets/post_assets/inf4-mlp/images/compressed/elastic_deformation_post.png",
    caption: "Digits from MNIST dataset with elastic deformation applied to them, to generate additional training samples, as part of Data Augmentation.",
    id: "elastic_deformation_post"
  }
category: projects
course_name: Inf4 - Machine Learning Practical
project_title: "Image Classification using DNN and CNN"
thumb_text: Deep learning classification with both ground-up Python solution on MNIST, and TensorFlow on CIFAR.
collaborators:
tech:
  - Deep Learning
  - TensorFlow
  - TensorBoard
  - Python
  - Numpy
  - Jupyter Notebooks
  - Linux
size: large

---

<div class="post-content-markdown">

The practical provided the opportunity to put both basic deep learning ideas into practice, and explore the slightly more advanced topic of Convolutional Neural Networks on MNIST, CIFAR-10 and CIFAR-100 datasets.
{: .text-left}

For tasks 1 and 2, the basic neural network components written in Python were provided, but often with the more advanced implementations left for us to fill in, e.g. modifications to the optimizer to support learning rate decay. Here, we only used MNIST.
{: .text-left}

In tasks 3 and 4 we used TensorFlow and both Densely connected neural networks, and  Convolutional Neural Networks to classify images in CIFAR-10 and CIFAR-100 datasets.
{: .text-left}

* **Task 1:** Establish a baseline for MNIST classification using densely connected neural networks and investigating different learning rate schedules.
* **Task 2:** Experiment with different network configurations, observing how much different layer count, hyperparameter tuning and batch normalization can increase the classification accuracy above the baseline. Data augmentation was used due to limited datasets and provided good results.
* **Task 3:** Perform experiments to determine the baseline accuracy that a densely connected neural network can achieve. I have experimented with different numbers of hidden units, epochs, activation functions, adaptive learning rate variations and dropout.
 * **Task 4:** Investigate the use of Convolutional neural networks for image recognition in CIFAR-10 and CIFAR-100 datasets. Here I have experimented with CNNs, different network configurations, hyperparameters, as well as dropout, fractional max-pooling and data augmentation.
{: .text-left}

Reports: [Google Drive](https://drive.google.com/open?id=1ivjc3oO2prNyn2vHfLZhiUSz4JXDk7lf){:target="_blank"}
{: .text-center}
Code Repository: [GitLab](https://gitlab.com/LinasKo/Inf4-MLP){:target="_blank"}
{: .text-center}

</div>
